{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizar_svc(params, r = results0):\n",
    "    C = params[0]\n",
    "    kernel = params[1]\n",
    "    gamma = params[2]\n",
    "\n",
    "    #print(params)\n",
    "    \n",
    "    modelo = SVC(random_state = 7,\n",
    "                 C = C,\n",
    "                 kernel = kernel,\n",
    "                 gamma = gamma)\n",
    "    \n",
    "    R = r[r[\"Métrica Média\"] == r[\"Métrica Média\"].max()].values[0]\n",
    "    \n",
    "    escala = {\"Original\": None,\n",
    "              \"MinMaxScaler\": preprocessing.MinMaxScaler(feature_range = (0, 1)),\n",
    "              \"StandardScaler\": preprocessing.StandardScaler(),\n",
    "              \"RobustScaler\": preprocessing.RobustScaler(),\n",
    "              \"MaxAbsScaler\": preprocessing.MaxAbsScaler(),\n",
    "              \"Normalizer\": preprocessing.Normalizer()}\n",
    "    \n",
    "    metricas = {\"acc\": \"accuracy\"}\n",
    "    \n",
    "    resultados = cross_validate(make_pipeline(escala[R[1]], modelo), X, Y, cv = 5, scoring = metricas)\n",
    "    \n",
    "    return - sum(resultados[\"test_acc\"]) / 5\n",
    "\n",
    "espaco = [(1.0, 100.0),\n",
    "          (\"rbf\", \"poly\", \"linear\", \"sigmoid\"),\n",
    "          (\"scale\", \"auto\")]\n",
    "\n",
    "resultados_otimizacao = gp_minimize(minimizar_svc, espaco, random_state = 7, n_calls = 200, n_random_starts = 10, verbose = False)\n",
    "\n",
    "def iteracoes(resulta, arq, titulo = \"Precisão\"):\n",
    "    figure(figsize = (20,10))\n",
    "    resulta.func_vals[0] = resulta.func_vals[1]\n",
    "    plot_convergence(resulta)\n",
    "    plt.title(\"%s x Iterações\" %(titulo), fontsize = 30)\n",
    "    plt.xlabel(\"Número de Iterações\", fontsize = 30)\n",
    "    plt.ylabel(\"Precisão Média\", fontsize = 30)\n",
    "    plt.grid(color = 'black', linestyle = '-', linewidth = 2.5)\n",
    "    plt.savefig(arq)\n",
    "    plt.show()\n",
    "\n",
    "iteracoes(resultados_otimizacao, \"imagem_diabetes_svc.png\", \"Acurácia\")\n",
    "    \n",
    "#display(Image(filename='imagem_diabetes_svc.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizar_rfc(params, r = results1):\n",
    "    n_estimators = params[0]\n",
    "    max_depth = params[1]\n",
    "    min_samples_split = params[2]\n",
    "    min_samples_leaf = params[3]\n",
    "    \n",
    "    #print(params)\n",
    "    \n",
    "    modelo = RandomForestClassifier(random_state = 7,\n",
    "                                    n_estimators = n_estimators,\n",
    "                                    max_depth = max_depth,\n",
    "                                    min_samples_split = min_samples_split,\n",
    "                                    min_samples_leaf = min_samples_leaf)\n",
    "\n",
    "    R = r[r[\"Métrica Média\"] == r[\"Métrica Média\"].max()].values[0]\n",
    "    \n",
    "    escala = {\"Original\": None,\n",
    "              \"MinMaxScaler\": preprocessing.MinMaxScaler(feature_range = (0, 1)),\n",
    "              \"StandardScaler\": preprocessing.StandardScaler(),\n",
    "              \"RobustScaler\": preprocessing.RobustScaler(),\n",
    "              \"MaxAbsScaler\": preprocessing.MaxAbsScaler(),\n",
    "              \"Normalizer\": preprocessing.Normalizer()}\n",
    "    \n",
    "    metricas = {\"acc\": \"accuracy\"}\n",
    "    \n",
    "    resultados = cross_validate(make_pipeline(escala[R[1]], modelo), X, Y, cv = 5, scoring = metricas)\n",
    "    \n",
    "    return - sum(resultados[\"test_acc\"]) / 5\n",
    "\n",
    "espaco = [(100, 200, 300, 400, 500, 600, 700),\n",
    "          (None, 2, 5, 7, 10, 15, 20, 25),\n",
    "          (2, 20),\n",
    "          (1, 20)]\n",
    "\n",
    "resultados_otimizacao = gp_minimize(minimizar_rfc, espaco, random_state = 7, n_calls = 200, n_random_starts = 10, verbose = False)\n",
    "\n",
    "iteracoes(resultados_otimizacao, \"imagem_diabetes_rfc.png\")    \n",
    "\n",
    "#display(Image(filename='imagem_diabetes_rfc.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizar_mlp(params, r = results):\n",
    "    alpha = params[0]\n",
    "    solver = params[1]\n",
    "    power_t = params[2]\n",
    "    beta_1 = params[3]\n",
    "    beta_2 = params[4]\n",
    "    n_iter_no_change = params[5]\n",
    "    activation = params[6]\n",
    "    learning_rate = params[7]\n",
    "    \n",
    "    #print(params)\n",
    "    \n",
    "    modelo = MLPRegressor(random_state = 7,\n",
    "                           alpha = alpha,\n",
    "                           solver = solver,\n",
    "                           power_t = power_t,\n",
    "                           beta_1 = beta_1,\n",
    "                           beta_2 = beta_2,\n",
    "                           n_iter_no_change = n_iter_no_change,\n",
    "                           activation = activation,\n",
    "                           learning_rate = learning_rate)\n",
    "    \n",
    "    R = r[r[\"Métrica Média\"] == r[\"Métrica Média\"].max()].values[0]\n",
    "    \n",
    "    escala = {\"Original\": None,\n",
    "              \"MinMaxScaler\": preprocessing.MinMaxScaler(feature_range = (0, 1)),\n",
    "              \"StandardScaler\": preprocessing.StandardScaler(),\n",
    "              \"RobustScaler\": preprocessing.RobustScaler(),\n",
    "              \"MaxAbsScaler\": preprocessing.MaxAbsScaler()}\n",
    "    \n",
    "    metricas = {\"r2\": \"r2\"}\n",
    "    \n",
    "    resultados = cross_validate(make_pipeline(escala[R[1]], modelo), X, Y, cv = 5, scoring = metricas)\n",
    "    \n",
    "    return - sum(resultados[\"test_r2\"]) / 5\n",
    "\n",
    "\n",
    "espaco = [(0.0001, 100.1),\n",
    "          (\"lbfgs\", \"sgd\", \"adam\"),\n",
    "          (0.5, 50.0),\n",
    "          (0.009, 0.9),\n",
    "          (0.05, 0.999),\n",
    "          (10, 100),\n",
    "          (\"identity\", \"logistic\", \"tanh\", \"relu\"),\n",
    "          (\"constant\", \"invscaling\", \"adaptive\")]\n",
    "\n",
    "resultados_otimizacao = gp_minimize(minimizar_mlp, espaco, random_state = 1, n_calls = 150, n_random_starts = 10, verbose = False)\n",
    "\n",
    "def iteracoes():\n",
    "    figure(figsize=(20,10))\n",
    "    resultados_otimizacao.func_vals[0] = resultados_otimizacao.func_vals[1]\n",
    "    plot_convergence(resultados_otimizacao)\n",
    "    plt.title(\"R2 x Iterações\")\n",
    "    plt.xlabel(\"Número de Iterações\")\n",
    "    plt.ylabel(\"R2\")\n",
    "    plt.grid(color = 'black', linestyle = '-', linewidth = 2)\n",
    "    plt.savefig('imagem_mlp.png')\n",
    "    plt.show()\n",
    "\n",
    "iteracoes()\n",
    "    \n",
    "#display(Image(filename='imagem_mlp.png')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizar_lg(params, r = results0):\n",
    "    C = params[0]\n",
    "    fit_intercept = params[1]\n",
    "    solver = params[2]\n",
    "\n",
    "    #print(params)\n",
    "    \n",
    "    modelo = LogisticRegression(random_state = 7,\n",
    "                                C = C,\n",
    "                                fit_intercept = fit_intercept,\n",
    "                                solver = solver)\n",
    "    \n",
    "    R = r[r[\"Métrica Média\"] == r[\"Métrica Média\"].max()].values[0]\n",
    "    \n",
    "    escala = {\"Original\": None,\n",
    "              \"MinMaxScaler\": preprocessing.MinMaxScaler(feature_range = (0, 1)),\n",
    "              \"StandardScaler\": preprocessing.StandardScaler(),\n",
    "              \"RobustScaler\": preprocessing.RobustScaler(),\n",
    "              \"MaxAbsScaler\": preprocessing.MaxAbsScaler(),\n",
    "              \"Normalizer\": preprocessing.Normalizer()}\n",
    "    \n",
    "    metricas = {\"acc\": \"accuracy\"}\n",
    "    \n",
    "    resultados = cross_validate(make_pipeline(escala[R[1]], modelo), X, Y, cv = 5, scoring = metricas)\n",
    "    \n",
    "    return - sum(resultados[\"test_acc\"]) / 5\n",
    "\n",
    "espaco = [(1.0, 500.0),\n",
    "          (False, True),\n",
    "          (\"newton-cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\")]\n",
    "\n",
    "resultados_otimizacao = gp_minimize(minimizar_lg, espaco, random_state = 7, n_calls = 100, n_random_starts = 10, verbose = False)\n",
    "\n",
    "def iteracoes(resulta, arq, titulo = \"Precisão\"):\n",
    "    figure(figsize = (20,10))\n",
    "    resulta.func_vals[0] = resulta.func_vals[1]\n",
    "    plot_convergence(resulta)\n",
    "    plt.title(\"%s x Iterações\" %(titulo), fontsize = 30)\n",
    "    plt.xlabel(\"Número de Iterações\", fontsize = 30)\n",
    "    plt.ylabel(\"Precisão Média\", fontsize = 30)\n",
    "    plt.grid(color = 'black', linestyle = '-', linewidth = 2.5)\n",
    "    plt.savefig(arq)\n",
    "    plt.show()\n",
    "\n",
    "iteracoes(resultados_otimizacao, \"imagem_diabetes_lg.png\", \"Acurácia\")\n",
    "    \n",
    "#display(Image(filename='imagem_diabetes_lg.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizar_catc(params, r = results0):\n",
    "    learning_rate = params[0]\n",
    "    l2_leaf_reg = params[1]\n",
    "    depth = params[2]\n",
    "    iterations = params[3]\n",
    "    od_type = params[4]\n",
    "    random_strength = params[5]\n",
    "    od_wait = params[6]\n",
    "    \n",
    "    #print(params)\n",
    "    \n",
    "    modelo = CatBoostClassifier(random_state = 7,\n",
    "                                verbose = False,\n",
    "                                learning_rate = learning_rate,\n",
    "                                l2_leaf_reg = l2_leaf_reg,\n",
    "                                depth = depth,\n",
    "                                iterations = iterations,\n",
    "                                od_type = od_type,\n",
    "                                random_strength = random_strength,\n",
    "                                od_wait = od_wait,\n",
    "                                boosting_type = \"Plain\",\n",
    "                                bootstrap_type = \"Bernoulli\")\n",
    "    \n",
    "    R = r[r[\"Acurácia Média\"] == r[\"Acurácia Média\"].max()].values[0]\n",
    "    \n",
    "    escala = {\"Original\": None,\n",
    "              \"MinMaxScaler\": preprocessing.MinMaxScaler(feature_range = (0, 1)),\n",
    "              \"StandardScaler\": preprocessing.StandardScaler(),\n",
    "              \"RobustScaler\": preprocessing.RobustScaler(),\n",
    "              \"MaxAbsScaler\": preprocessing.MaxAbsScaler()}\n",
    "    \n",
    "    metricas = {\"acc\": \"accuracy\"}\n",
    "    \n",
    "    resultados = cross_validate(make_pipeline(escala[R[1]], modelo), X, Y, cv = 5, scoring = metricas)\n",
    "    \n",
    "    return - sum(resultados[\"test_acc\"]) / 5\n",
    "\n",
    "\n",
    "espaco = [(0.0001, 1.0),\n",
    "          (1, 9),\n",
    "          (4, 10),\n",
    "          (200, 500),\n",
    "          (\"IncToDec\", \"Iter\"),\n",
    "          (0.01, 10.0),\n",
    "          (10, 30)]\n",
    "\n",
    "resultados_otimizacao = gp_minimize(minimizar_catc, espaco, random_state = 1, n_calls = 200, n_random_starts = 10, verbose = False)\n",
    "\n",
    "def iteracoes():\n",
    "    figure(figsize = (20,10))\n",
    "    resultados_otimizacao.func_vals[0] = resultados_otimizacao.func_vals[1]\n",
    "    plot_convergence(resultados_otimizacao)\n",
    "    plt.title(\"R2 x Iterações\")\n",
    "    plt.xlabel(\"Número de Iterações\")\n",
    "    plt.ylabel(\"R2\")\n",
    "    plt.grid(color = 'black', linestyle = '-', linewidth = 2)\n",
    "    plt.savefig('imagem_cat.png')\n",
    "    plt.show()\n",
    "    \n",
    "iteracoes()\n",
    "    \n",
    "#display(Image(filename='imagem_mlp.png')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimizar_knn(params, r = results1):\n",
    "    n_neighbors = params[0]\n",
    "    weights = params[1]\n",
    "    algorithm = params[2]\n",
    "    leaf_size = params[3]\n",
    "    p = params[4]\n",
    "\n",
    "    #print(params)\n",
    "    \n",
    "    modelo = KNeighborsClassifier(n_neighbors = n_neighbors,\n",
    "                                  weights = weights,\n",
    "                                  algorithm = algorithm,\n",
    "                                  leaf_size = leaf_size,\n",
    "                                  p = p)\n",
    "    \n",
    "    R = r[(r[\"Acurácia Média\"] + r[\"Recall Médio\"]) == (r[\"Acurácia Média\"] + r[\"Recall Médio\"]).max()].values[0]\n",
    "    \n",
    "    escala = {\"Original\": None,\n",
    "              \"MinMaxScaler\": preprocessing.MinMaxScaler(feature_range = (0, 1)),\n",
    "              \"StandardScaler\": preprocessing.StandardScaler(),\n",
    "              \"RobustScaler\": preprocessing.RobustScaler(),\n",
    "              \"MaxAbsScaler\": preprocessing.MaxAbsScaler(),\n",
    "              \"Normalizer\": preprocessing.Normalizer(),\n",
    "              \"QuantileTransformer\": preprocessing.QuantileTransformer()}\n",
    "    \n",
    "    metricas = {\"acc\": \"accuracy\"}\n",
    "    \n",
    "    resultados = cross_validate(make_pipeline(escala[R[2]], modelo), X, Y, cv = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 7), scoring = metricas)\n",
    "    \n",
    "    return - sum(resultados[\"test_acc\"]) / 5\n",
    "\n",
    "espaco = [(1, 3, 5, 7, 9, 11),\n",
    "          (\"uniform\", \"distance\"),\n",
    "          (\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"),\n",
    "          (10, 90),\n",
    "          (1, 10)]\n",
    "\n",
    "resultados_otimizacao = gp_minimize(minimizar_knn, espaco, random_state = 7, n_calls = 75, n_random_starts = 10, verbose = False)\n",
    "\n",
    "def iteracoes(resulta, arq, titulo = \"Precisão\"):\n",
    "    figure(figsize = (20,10))\n",
    "    resulta.func_vals[0] = resulta.func_vals[1]\n",
    "    plot_convergence(resulta)\n",
    "    plt.title(\"%s x Iterações\" %(titulo), fontsize = 30)\n",
    "    plt.xlabel(\"Número de Iterações\", fontsize = 30)\n",
    "    plt.ylabel(\"Precisão Média\", fontsize = 30)\n",
    "    plt.grid(color = 'black', linestyle = '-', linewidth = 2.5)\n",
    "    plt.savefig(arq)\n",
    "    plt.show()\n",
    "\n",
    "iteracoes(resultados_otimizacao, \"imagem_breast_knn.png\", \"Acurácia\")\n",
    "    \n",
    "#display(Image(filename='imagem_breast_knn.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
